{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201b27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aaf6a236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "product_code         0\n",
       "loading            250\n",
       "attribute_0          0\n",
       "attribute_1          0\n",
       "attribute_2          0\n",
       "attribute_3          0\n",
       "measurement_0        0\n",
       "measurement_1        0\n",
       "measurement_2        0\n",
       "measurement_3      381\n",
       "measurement_4      538\n",
       "measurement_5      676\n",
       "measurement_6      796\n",
       "measurement_7      937\n",
       "measurement_8     1048\n",
       "measurement_9     1227\n",
       "measurement_10    1300\n",
       "measurement_11    1468\n",
       "measurement_12    1601\n",
       "measurement_13    1774\n",
       "measurement_14    1874\n",
       "measurement_15    2009\n",
       "measurement_16    2110\n",
       "measurement_17    2284\n",
       "failure              0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518</td>\n",
       "      <td>15.748</td>\n",
       "      <td>19.292</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.89</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540</td>\n",
       "      <td>17.717</td>\n",
       "      <td>17.893</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.43</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652</td>\n",
       "      <td>16.738</td>\n",
       "      <td>18.240</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.07</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188</td>\n",
       "      <td>18.576</td>\n",
       "      <td>18.339</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.06</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950</td>\n",
       "      <td>16.990</td>\n",
       "      <td>15.746</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26565</th>\n",
       "      <td>158.95</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16.301</td>\n",
       "      <td>13.259</td>\n",
       "      <td>18.068</td>\n",
       "      <td>15.505</td>\n",
       "      <td>10.865</td>\n",
       "      <td>19.354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572</td>\n",
       "      <td>16.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26566</th>\n",
       "      <td>146.02</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>17.543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.984</td>\n",
       "      <td>19.078</td>\n",
       "      <td>11.139</td>\n",
       "      <td>19.563</td>\n",
       "      <td>11.242</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471</td>\n",
       "      <td>853.924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26567</th>\n",
       "      <td>115.62</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15.670</td>\n",
       "      <td>11.535</td>\n",
       "      <td>16.778</td>\n",
       "      <td>18.385</td>\n",
       "      <td>11.630</td>\n",
       "      <td>19.279</td>\n",
       "      <td>11.407</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065</td>\n",
       "      <td>750.364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26568</th>\n",
       "      <td>106.38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>18.059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.918</td>\n",
       "      <td>18.101</td>\n",
       "      <td>11.713</td>\n",
       "      <td>19.358</td>\n",
       "      <td>11.392</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865</td>\n",
       "      <td>730.156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>131.20</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18.034</td>\n",
       "      <td>11.431</td>\n",
       "      <td>16.918</td>\n",
       "      <td>17.129</td>\n",
       "      <td>12.713</td>\n",
       "      <td>18.731</td>\n",
       "      <td>10.611</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890</td>\n",
       "      <td>602.354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26570 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1   2   3       4       5       6       7       8       9   \\\n",
       "0       80.10   7   8   4  18.040  12.518  15.748  19.292  11.739  20.155   \n",
       "1       84.89  14   3   3  18.213  11.540  17.717  17.893  12.748  17.889   \n",
       "2       82.43  12   1   5  18.057  11.652  16.738  18.240  12.718  18.288   \n",
       "3      101.07  13   2   6  17.295  11.188  18.576  18.339  12.583  19.060   \n",
       "4      188.06   9   2   8  19.346  12.950  16.990  15.746  11.306  18.093   \n",
       "...       ...  ..  ..  ..     ...     ...     ...     ...     ...     ...   \n",
       "26565  158.95   6  16   4  16.301  13.259  18.068  15.505  10.865  19.354   \n",
       "26566  146.02  10  12   8  17.543     NaN  17.984  19.078  11.139  19.563   \n",
       "26567  115.62   1  10   1  15.670  11.535  16.778  18.385  11.630  19.279   \n",
       "26568  106.38   2   9   4  18.059     NaN  16.918  18.101  11.713  19.358   \n",
       "26569  131.20   6  19   1  18.034  11.431  16.918  17.129  12.713  18.731   \n",
       "\n",
       "           10      11      12      13      14      15      16      17  \\\n",
       "0      10.672  15.859  17.594  15.193  15.029     NaN  13.034  14.684   \n",
       "1      12.448  17.947  17.915  11.755  14.732  15.425  14.395  15.631   \n",
       "2      12.715  15.607     NaN  13.798  16.711  18.631  14.094  17.946   \n",
       "3      12.471  16.346  18.377  10.020  15.250  15.562  16.154  17.172   \n",
       "4      10.337  17.082  19.932  12.428  16.182  12.760  13.153  16.412   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "26565     NaN  12.177  17.942  10.112  15.795  18.572  16.144     NaN   \n",
       "26566  11.242  14.179  20.564  10.234  14.450  14.322  13.146  16.471   \n",
       "26567  11.407  16.437  17.476   8.668  15.069  16.599  15.590  14.065   \n",
       "26568  11.392  17.064  17.814  14.928  16.273  15.485  13.624  12.865   \n",
       "26569  10.611  15.603  19.703  11.006  15.875  13.366  16.527  17.890   \n",
       "\n",
       "            18  19  \n",
       "0      764.100   0  \n",
       "1      682.057   0  \n",
       "2      663.376   0  \n",
       "3      826.282   0  \n",
       "4      579.885   0  \n",
       "...        ...  ..  \n",
       "26565  729.131   0  \n",
       "26566  853.924   0  \n",
       "26567  750.364   0  \n",
       "26568  730.156   0  \n",
       "26569  602.354   0  \n",
       "\n",
       "[26570 rows x 20 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "display(train.isnull().sum())\n",
    "train['loading'].fillna(value=127.74233678955453, inplace=True)\n",
    "train.drop(['id', 'product_code', 'attribute_0', 'attribute_1', 'attribute_2', 'attribute_3'], axis='columns', inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.columns = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2c07a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0   1   2  3       4           5       6       7       8       9  \\\n",
      "0       80.10   7   8  4  18.040   12.518000  15.748  19.292  11.739  20.155   \n",
      "1       84.89  14   3  3  18.213   11.540000  17.717  17.893  12.748  17.889   \n",
      "2       82.43  12   1  5  18.057   11.652000  16.738  18.240  12.718  18.288   \n",
      "3      101.07  13   2  6  17.295   11.188000  18.576  18.339  12.583  19.060   \n",
      "4      188.06   9   2  8  19.346   12.950000  16.990  15.746  11.306  18.093   \n",
      "...       ...  ..  .. ..     ...         ...     ...     ...     ...     ...   \n",
      "26565  158.95   6  16  4  16.301   13.259000  18.068  15.505  10.865  19.354   \n",
      "26566  146.02  10  12  8  17.543  127.753606  17.984  19.078  11.139  19.563   \n",
      "26567  115.62   1  10  1  15.670   11.535000  16.778  18.385  11.630  19.279   \n",
      "26568  106.38   2   9  4  18.059  127.753606  16.918  18.101  11.713  19.358   \n",
      "26569  131.20   6  19  1  18.034   11.431000  16.918  17.129  12.713  18.731   \n",
      "\n",
      "       ...      11          12      13      14          15      16  \\\n",
      "0      ...  15.859   17.594000  15.193  15.029  127.753606  13.034   \n",
      "1      ...  17.947   17.915000  11.755  14.732   15.425000  14.395   \n",
      "2      ...  15.607  127.753606  13.798  16.711   18.631000  14.094   \n",
      "3      ...  16.346   18.377000  10.020  15.250   15.562000  16.154   \n",
      "4      ...  17.082   19.932000  12.428  16.182   12.760000  13.153   \n",
      "...    ...     ...         ...     ...     ...         ...     ...   \n",
      "26565  ...  12.177   17.942000  10.112  15.795   18.572000  16.144   \n",
      "26566  ...  14.179   20.564000  10.234  14.450   14.322000  13.146   \n",
      "26567  ...  16.437   17.476000   8.668  15.069   16.599000  15.590   \n",
      "26568  ...  17.064   17.814000  14.928  16.273   15.485000  13.624   \n",
      "26569  ...  15.603   19.703000  11.006  15.875   13.366000  16.527   \n",
      "\n",
      "               17       18  19  Set  \n",
      "0       14.684000  764.100   0    0  \n",
      "1       15.631000  682.057   0    0  \n",
      "2       17.946000  663.376   0    0  \n",
      "3       17.172000  826.282   0    0  \n",
      "4       16.412000  579.885   0    0  \n",
      "...           ...      ...  ..  ...  \n",
      "26565  127.753606  729.131   0    0  \n",
      "26566   16.471000  853.924   0    1  \n",
      "26567   14.065000  750.364   0    0  \n",
      "26568   12.865000  730.156   0    0  \n",
      "26569   17.890000  602.354   0    0  \n",
      "\n",
      "[26570 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 19\n",
    "if \"Set\" not in train.columns:\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.8, .1], size=(train.shape[0],))\n",
    "    \n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "# test_indices = train[train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c0b8bedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33bbddaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 29\n",
      "2 30\n",
      "3 25\n",
      "19 2\n",
      "Set 2\n"
     ]
    }
   ],
   "source": [
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "# Categorical Embedding을 위해 Categorical 변수의 차원과 idxs를 담음.\n",
    "unused_feat = ['Set']\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "\n",
    "\n",
    "X_train = train[features].values[train_indices]\n",
    "y_train = train[target].values[train_indices]\n",
    "\n",
    "X_valid = train[features].values[valid_indices]\n",
    "y_valid = train[target].values[valid_indices]\n",
    "\n",
    "# X_test = train[features].values[test_indices]\n",
    "# y_test = train[target].values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2885673a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 19), dtype=float64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2280b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=10,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-2),\n",
    "                       scheduler_params={\"step_size\":50,\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='sparsemax' # \"sparsemax\", entmax\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e262d9ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m max_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\kaggle_TPS2208\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:183\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m=\u001b[39m loss_fn\n\u001b[1;32m--> 183\u001b[0m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_fit_params(\n\u001b[0;32m    186\u001b[0m     X_train,\n\u001b[0;32m    187\u001b[0m     y_train,\n\u001b[0;32m    188\u001b[0m     eval_set,\n\u001b[0;32m    189\u001b[0m     weights,\n\u001b[0;32m    190\u001b[0m )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Validate and reformat eval set depending on training data\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\kaggle_TPS2208\\lib\\site-packages\\sklearn\\utils\\validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    916\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=max_epochs , patience=20,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ca741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
